---
title: "Manually parsing the McStas DSL"
---


# Text Parsing is Fun

Recently while researching and learning more C, I happened upon custom parsing and thought it was pretty cool. Turns out that people have been parsing many things manually since way back when, and done it very well.

Parsing sometimes gets a bad rep afterall, and seems like a thing that "should just work", something we should have tools for.

Plenty tools were indeed written during the Bell Labs era and given names like Yacc or (later on) BisonP. These were ancestors of the infamous GNU, one of the most hoofed software animal coming out of the 1980's.

Yet at closer look, parsing is not just about reading JSON files or writing custom compilers, supposedly a common practice in those days. It probably owes its fame to one of the wildest  programming paradigms: META programming.

In an attempt to explain the importance of meta programming to a non-programmer, I'd point to the widespread usage of scripting languages like Python, JavaScript, Ruby, and Perl. All very wide-spread and with a feature called "reflecting" which is notably lacking in C.


# What is META programming?

Meta programming means writing a program that writes ANOTHER program. This is admittedly a two-step process: First you write and execute a program that outputs the source code for another program, which is compiled and executed separately, and often automatically.

With meta programming we may configure certain things abstractly, let the meta process take its course, and reap the automated benefits, rather than writing everything "down-stream" out in tedious detail, tedious - but necessary.

If this sounds a bit complicated, well, it is: Meta programs are incomprehensible to anyone but their authors. Meta programs remind me of convoluted math proofs that skip way too many steps.

Despite the potential for obscurity, meta programming comes with enormous power, and allows us to do many things that are quite clever and time-saving.


# Are we still using that?

(I worked on the open-source software package McStas as a core developer, during my employment at DTU Physics 2015-2020, which is why I know so much about it.)

Also McStas, a physics simulation package originally dating from 1997, was indeed written by people wielding the power of META. As a physics simulation, performance requirements dictated that it was written in C. Thus the meta program had to output C code.

Why not write the meta program in C, too? This was not as uncommon as it sounds, back then, and to this day, C is very dependable and portable.

So from a certain perspective it was a pretty great choice. However let's circle back to those furry software animals mentioned above, specifically BISON and FLEX.

The BISON/FLEX combo is known as a parser generator. It is not just a parser, nor just a code generator. It is a parser that uses code generation to generate a parser. Spoken plainly, it is a C program that takes a few configuration files and outputs C source code for a parser.


# Overly contrived example

In the BISON/FLEX system you write rules that dictate how input text must be structured to be accepted as a valid meta program - meaning the allowed words, sentences and sequences.

For example, let's insist that an email must contain the following elements:

<pre>
"email: greeting body farewell"
</pre>

Breaking it down further, the "greeting" could be defined as

<pre>
"greeting: formality name"
"body: TEXT"
"farewell: formality name"
</pre>

With this, we must go on to define what qualifies as a "formality" and a "name". A name must be capitalized, a formality belongs to a group of specific phrases, and so on and so forth. If we keep up this definition process, we will at some point have described an email well enough for our purposes.

This is what's called a "domain specific language" or DSL for short.

Notice how the rules above are written in an abstract and beautiful way that resembles mathematics. Amazing, isn't it?


# Experimental physics cross-over

Imagine an experimental physicist with sporadic access to highly expensive and complex equipment. This "instrument" must be configured exactly right for the experiment to be a success - but we don't have access to it beforehand.

In order to solve this connundrum, we resort to simulation. We simulate the experiment in software, allowing us to tweak the setup and plan the (virtual) experiment. The simulation could even show you how to configure the equipment optimally, which is great, then we don't have to spend (as much) time tuning the instrument on-site.

Since simulation code is fickle and complicated, we use-existing software components which match the physical instrument as closely as possible. We don't want to write the whole simulation program from scratch - although people in the real reality actually did for years - until better options was developed. One of these "better options" is called McStas.

In other words, people created easier ways to configure their simulation in terms of pre-written software components. To keep it all neat and tight, they used BISON/FLEX to create the parser that would make all this happen.

This parser would convert two types of configuration files - components and instruments - into finished simulation programs. This tool is then called mcstas (and mcxtrace), and the  rules that govern how these configuration files must be written, is called the McStas DSL.


# McStas is not optimized for further development

This software strategy was a great success, and it still is. But like most software it has its issues and limitations and a few vectors of potential improvement.

Presented below are three major issues with the system as-is.

The FLEX/BISON setup is rather convoluted. In order to use it, you need to keep track of grammar-rules (.y) and lexer (.l) files. The flex/bison command-line tools take these configuration files as their input, and outputs the C code which comprise the actual DSL parser.

This takes a few steps, so when *debugging* we have to go through the entire build process:

- 1) edit the flex/bison configuration files
- 2) execute flex/bison cli tools
- 3) include the generated parser code into the 'mcstas' tool and compile
- 4) run the generated mcstas parser-tool on a sample instrument file
- 5) the mcstas parser how outputs source code for the simulation
- 6) compile the simulation source
- 7) run the executable and check this simulation's output files (using other tools)

The process is automated, but we might be hard pressed to use this level of automation and still retain a convenient/efficient development setup.

### Problem a) The lack of a convenient development loop

The build process is lengthy and inconvenient for tight development loops, and quite hard to debug.

We can't debug the parser itself since flex/bison files can't be debugged and the resulting parser code is incomprehensible and not to be trifled with.

The generated simulation code is monolithic and hard to read and navigate.

### Problem b) Error messages are very generic

Another consequence of using flex/bison is that the error codes are quite generic.

This means that when users work with their instruments they may have a hard time figuring out what that error message even means. The line numbers are generated, but beyond a few special cases, there isn't any more information to go by.

It isn't terrible, but still leaves a lot to be desired in terms of usability.

### Problem c) Inaccessible simulation core algorithms

The biggest problem with the current mcstas setup from a developer's perspective, is the inaccessibility of the core algorithms. For years, mcstas has run the same simulation original ray tracing loop.

At some point, MPI was introduced, and it has also been ported to GPUs with a tool called OpenACC. To make the OpenACC port possible, we had to heavily edit the code generator at the time, again using the long-winded process sketched above. These changes brought performance improvements, but no now capabilities, and came at a significant complexity cost.

It bears mentioning that the mcstas code generator is tightly linked to the parser, since the parser collects data and passes it on for reading and processing by the code generator.

Thus experimenting with the core algorithms was not something that came naturally in an afternoon of recreational programming. And if the core developers mostly didn't, why should users even try?


# Can legacy code be fixed or salvaged?

The assumption was always that writing a parser - and thus another code generator as well - in any other way, was either unfeasible or unviable in terms of time invested.

So for 25 years, the ring build-system lay dormant at the bottom of the Rhine, awaiting the programmers to reclaim it ...

People have thus built tools on top of the mcstas core and developed onion rings of software stacks (ss you do). Mostly these days, the basic simulation tools seem to rest quietly below.

For whatever reason, I started writing a parser for the mcstas DSL during the 2020 pandemic. Writing it was a delightful and satisfying experience, and a few months ago I took up the project with the intention of finishing the work, write a nice prototype and present it as a possible alternative / of academic interest.

Today a working prototype of <code>mcparse</code> is available here: [mcparse].

To prove its validity, I wrote a code generator to match. In the 'mctrace' project, this generated code is combined with other custom algorithms and tools to produce real run-time simulation output and graphics.

It combines partially with the mcstas simulation core, also salvaged from the McCode project, and with custom ray-tracing procedures. This is described elsewhere, for now just an assertion that a working, proof-of-concept code-generator and simulation core exists.


# What Custom parsing brings to the table


Here's to the example outputs



[mcparse]: https://github.com/climbcat/mcparse

